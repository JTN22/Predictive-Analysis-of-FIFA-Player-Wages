# -*- coding: utf-8 -*-
"""Linear regression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EMbCwnabHDK0nvda8y-nj8D99jujj9cr
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Load the datasets
X_train = pd.read_csv('/Preprocessed_X_train.csv')
X_test = pd.read_csv('/Preprocessed_X_test.csv')
y_train = pd.read_csv('/Preprocessed_y_train.csv')
y_train = y_train.iloc[:, 0]
y_test = pd.read_csv('/Preprocessed_y_test.csv')
y_test = y_test.iloc[:, 0]

"""# Top 20 features from Preprocessed data"""

#Top 20 from preprocessed data

Preprocessed_features = [
    'overall_score', 'position_score', 'height', 'weight', 'age', 'Ball Control',
    'Dribbling', 'Slide Tackle', 'Stand Tackle', 'Aggression', 'Reactions',
    'Att. Position', 'Interceptions', 'Vision', 'Composure', 'Crossing',
    'Short Pass', 'Long Pass', 'Acceleration', 'Stamina', 'Strength', 'Balance',
    'Sprint Speed', 'Agility', 'Jumping'
]

X_Preprocessed_train = X_train[Preprocessed_features]
X_Preprocessed_test = X_test[Preprocessed_features]

    # Scale the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_Preprocessed_train)
X_test_scaled = scaler.transform(X_Preprocessed_test)

    # Train the model
model = LinearRegression()
model.fit(X_train_scaled, y_train)

    # Make predictions
y_pred = model.predict(X_test_scaled)

    # Calculate metrics
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

    # Get feature importance
feature_importance1 = pd.DataFrame({
                      'Feature': X_Preprocessed_train.columns,
                      'Coefficient': model.coef_
                      }).sort_values('Coefficient', ascending=False)

from google.colab import drive
drive.mount('/content/drive')

# Print model performance
print(f"Mean Squared Error: {mse:.2f}")
print(f"R² Score: {r2:.2f}")
print("\nTop 20 Most Important Features:")
print(feature_importance1.head(20))

print("\nTop 20 Features:")
# print(top_features)

# Plot the Top 20 Features
plt.figure(figsize=(12, 8))
plt.barh(feature_importance1['Feature'][::-1], feature_importance1['Coefficient'][::-1])
plt.xlabel('Importance Score')
plt.ylabel('Features')
plt.title('Top 20 Features (Linear Regression - preprocessed data)')
plt.tight_layout()
plt.show()

# Scatter plot of Actual vs Predicted values
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred, alpha=0.5)
plt.plot([y_test.min(), y_test.max()],
         [y_test.min(), y_test.max()],
         'k--', lw=2, color='red')
plt.title("Actual vs Predicted Wages")
plt.xlabel("Actual Wages")
plt.ylabel("Predicted Wages")
plt.show()

"""#XGBoost selected Top 20 features"""

#top 20 XGBoost selected features

XGBoost_features = ['Ball Control', 'Dribbling', 'Slide Tackle', 'Stand Tackle', 'Aggression',
                 'Reactions', 'Att. Position', 'Interceptions', 'Vision', 'Composure',
                 'Crossing', 'Short Pass', 'Long Pass', 'Acceleration', 'Stamina',
                 'Strength', 'Balance', 'Sprint Speed', 'Agility', 'Jumping']

X_XGBoost_train = X_train[XGBoost_features]
X_XGBoost_test = X_test[XGBoost_features]

    # Scale the features
scaler = StandardScaler()
X_train_scaled2 = scaler.fit_transform(X_XGBoost_train)
X_test_scaled2 = scaler.transform(X_XGBoost_test)

    # Train the model
model = LinearRegression()
model.fit(X_train_scaled2, y_train)

    # Make predictions
y_pred = model.predict(X_test_scaled2)

    # Calculate metrics
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

    # Get feature importance
feature_importance2 = pd.DataFrame({
                      'Feature': X_XGBoost_train.columns,
                      'Coefficient': model.coef_
                      }).sort_values('Coefficient', ascending=False)

# Print model performance
print(f"Mean Squared Error: {mse:.2f}")
print(f"R² Score: {r2:.2f}")
print("\nTop 20 Most Important Features:")
print(feature_importance2.head(20))

print("\nTop 20 Features:")
# print(top_features)

# Plot the Top 20 Features
plt.figure(figsize=(12, 8))
plt.barh(feature_importance1['Feature'][::-1], feature_importance1['Coefficient'][::-1])
plt.xlabel('Importance Score')
plt.ylabel('Features')
plt.title('Top 20 Features (Linear Regression - XGBoost selected)')
plt.tight_layout()
plt.show()

# Scatter plot of Actual vs Predicted values
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred, alpha=0.5)
plt.plot([y_test.min(), y_test.max()],
         [y_test.min(), y_test.max()],
         'k--', lw=2, color='red')
plt.title("Actual vs Predicted Wages")
plt.xlabel("Actual Wages")
plt.ylabel("Predicted Wages")
plt.show()