# -*- coding: utf-8 -*-
"""SVR.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mWOGhdpm7ZwB3i0DLOAQBuO_qFeYmDMt
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.svm import SVR
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.inspection import permutation_importance

# Load the datasets
X_train = pd.read_csv('Preprocessed_X_train.csv')
X_test = pd.read_csv('Preprocessed_X_test.csv')
y_train = pd.read_csv('Preprocessed_y_train.csv')
y_train = y_train.iloc[:, 0]
y_test = pd.read_csv('Preprocessed_y_test.csv')
y_test = y_test.iloc[:, 0]

"""# Model 1: SVR on features"""

# Train the SVR model
svr_model = SVR(kernel='rbf', C=100, epsilon=0.1)
svr_model.fit(X_train, y_train)

# Predict on test data
svr_y_pred = svr_model.predict(X_test)

# Visualization: Actual vs. Predicted Wage
plt.figure(figsize=(10, 6))
plt.scatter(y_test, svr_y_pred, alpha=0.5)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
plt.title("Actual vs Predicted Wage")
plt.xlabel("Actual Wage")
plt.ylabel("Predicted Wage")
plt.show()

# Calculate metrics
svr_mse = mean_squared_error(y_test, svr_y_pred)
svr_r2 = r2_score(y_test, svr_y_pred)

# Print performance metrics
print(f"SVR - Mean Squared Error: {svr_mse}")
print(f"SVR - R² Score: {svr_r2}")

# Visualize feature importance for the SVR model
result = permutation_importance(svr_model, X_test, y_test, n_repeats=1, random_state=42)
feature_list = list(zip(X_test.columns, result["importances_mean"]))
top_20_features = pd.DataFrame(sorted(feature_list, key=lambda x: x[1], reverse=True)[:20], columns=["Feature", "Importance"])

print("\nTop 20 Features:")
print(top_20_features)

# Plot feature importance
plt.figure(figsize=(12, 6))
plt.barh(top_20_features["Feature"], top_20_features["Importance"])
plt.title("SVR's Feature Importances")
plt.xlabel("Importance Score")
plt.ylabel("Feature")
plt.gca().invert_yaxis()
plt.tight_layout()
plt.show()

"""# Model 2: SVR on XGBoost's top 20 features"""

# Subset data for XGBoost's top 20 features
XGBoost_features = ['Ball Control', 'Dribbling', 'Slide Tackle', 'Stand Tackle', 'Aggression',
                 'Reactions', 'Att. Position', 'Interceptions', 'Vision', 'Composure',
                 'Crossing', 'Short Pass', 'Long Pass', 'Acceleration', 'Stamina',
                 'Strength', 'Balance', 'Sprint Speed', 'Agility', 'Jumping']

X_XGBoost_train = X_train[XGBoost_features]
X_XGBoost_test = X_test[XGBoost_features]

# Train the SVR model
svr_XGBoost_model = SVR(kernel='rbf', C=100, epsilon=0.1)
svr_XGBoost_model.fit(X_XGBoost_train, y_train)

# Predict on test data
svr_XGBoost_y_pred = svr_XGBoost_model.predict(X_XGBoost_test)

# Visualization: Actual vs. Predicted Wage
plt.figure(figsize=(10, 6))
plt.scatter(y_test, svr_XGBoost_y_pred, alpha=0.5)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
plt.title("Actual vs Predicted Wage")
plt.xlabel("Actual Wage")
plt.ylabel("Predicted Wage")
plt.show()

# Calculate metrics
svr_XGBoost_mse = mean_squared_error(y_test, svr_XGBoost_y_pred)
svr_XGBoost_r2 = r2_score(y_test, svr_XGBoost_y_pred)

# Print performance metrics
print(f"SVR on XGBoost's Top 20 Features - Mean Squared Error: {svr_XGBoost_mse}")
print(f"SVR on XGBoost's Top 20 Features - R² Score: {svr_XGBoost_r2}")

# Visualize feature importance for XGBoost's top 20 features
result = permutation_importance(svr_XGBoost_model, X_XGBoost_test, y_test, n_repeats=1, random_state=42)
feature_list = list(zip(X_XGBoost_test.columns, result["importances_mean"]))
top_20_features = pd.DataFrame(sorted(feature_list, key=lambda x: x[1], reverse=True)[:20], columns=["Feature", "Importance"])

print("\nTop 20 Features:")
print(top_20_features)

# Plot feature importance
plt.figure(figsize=(12, 6))
plt.barh(top_20_features["Feature"], top_20_features["Importance"])
plt.title("SVR's Feature Importances (XGBoost's Top 20)")
plt.xlabel("Importance Score")
plt.ylabel("Feature")
plt.gca().invert_yaxis()
plt.tight_layout()
plt.show()

"""# Model 3: SVR on Preprocessed's top 20 features"""

# Subset data for Preprocessed's top 20 features
Preprocessed_features = [
    'overall_score', 'position_score', 'height', 'weight', 'age', 'Ball Control',
    'Dribbling', 'Slide Tackle', 'Stand Tackle', 'Aggression', 'Reactions',
    'Att. Position', 'Interceptions', 'Vision', 'Composure', 'Crossing',
    'Short Pass', 'Long Pass', 'Acceleration', 'Stamina', 'Strength', 'Balance',
    'Sprint Speed', 'Agility', 'Jumping'
]

X_Preprocessed_train = X_train[Preprocessed_features]
X_Preprocessed_test = X_test[Preprocessed_features]

# Train the SVR model
svr_Preprocessed_model = SVR(kernel='rbf', C=100, epsilon=0.1)
svr_Preprocessed_model.fit(X_Preprocessed_train, y_train)

# Predict on test data
svr_Preprocessed_y_pred = svr_Preprocessed_model.predict(X_Preprocessed_test)

# Visualization: Actual vs. Predicted Wage
plt.figure(figsize=(10, 6))
plt.scatter(y_test, svr_Preprocessed_y_pred, alpha=0.5)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
plt.title("Actual vs Predicted Wage")
plt.xlabel("Actual Wage")
plt.ylabel("Predicted Wage")
plt.show()

# Calculate metrics
svr_Preprocessed_mse = mean_squared_error(y_test, svr_Preprocessed_y_pred)
svr_Preprocessed_r2 = r2_score(y_test, svr_Preprocessed_y_pred)

# Print performance metrics
print(f"SVR on Preprocessed's Top 20 Features - Mean Squared Error: {svr_Preprocessed_mse}")
print(f"SVR on Preprocessed's Top 20 Features - R² Score: {svr_Preprocessed_r2}")

# Visualize feature importance for Preprocessed's top 20 features
result = permutation_importance(svr_Preprocessed_model, X_Preprocessed_test, y_test, n_repeats=1, random_state=42)
feature_list = list(zip(X_Preprocessed_test.columns, result["importances_mean"]))
top_20_features = pd.DataFrame(sorted(feature_list, key=lambda x: x[1], reverse=True)[:20], columns=["Feature", "Importance"])

print("\nTop 20 Features:")
print(top_20_features)

# Plot feature importance
plt.figure(figsize=(12, 6))
plt.barh(top_20_features["Feature"], top_20_features["Importance"])
plt.title("SVR's Feature Importances (Preprocessed's Top 20)")
plt.xlabel("Importance Score")
plt.ylabel("Feature")
plt.gca().invert_yaxis()
plt.tight_layout()
plt.show()

"""# SqrtTransformers()"""

# Load the datasets
X_train_sqrt = pd.read_csv('Preprocessed_X_train_SqrtTransformer.csv')
X_test_sqrt = pd.read_csv('Preprocessed_X_test_SqrtTransformer.csv')
y_train_sqrt = pd.read_csv('Preprocessed_y_train_SqrtTransformer.csv')
y_train_sqrt = y_train_sqrt.iloc[:, 0]
y_test_sqrt = pd.read_csv('Preprocessed_y_test_SqrtTransformer.csv')
y_test_sqrt = y_test_sqrt.iloc[:, 0]

"""# Model 4: SVR on features (sqrt y_pred vs. sqrt y_test)"""

# Train the SVR model
svr_model = SVR(kernel='rbf', C=100, epsilon=0.1)
svr_model.fit(X_train_sqrt, y_train_sqrt)

# Predict on test data
svr_y_pred = svr_model.predict(X_test_sqrt)

# Visualization: Actual vs. Predicted Wage
plt.figure(figsize=(10, 6))
plt.scatter(y_test_sqrt, svr_y_pred, alpha=0.5)
plt.plot([y_test_sqrt.min(), y_test_sqrt.max()], [y_test_sqrt.min(), y_test_sqrt.max()], 'r--', lw=2)
plt.title("Actual vs Predicted Wage")
plt.xlabel("Actual Wage")
plt.ylabel("Predicted Wage")
plt.show()

# Calculate metrics
svr_mse = mean_squared_error(y_test_sqrt, svr_y_pred)
svr_r2 = r2_score(y_test_sqrt, svr_y_pred)

# Print performance metrics
print(f"SVR - Mean Squared Error: {svr_mse}")
print(f"SVR - R² Score: {svr_r2}")

# Visualize feature importance for the SVR model
result = permutation_importance(svr_model, X_test_sqrt, y_test_sqrt, n_repeats=1, random_state=42)
feature_list = list(zip(X_test_sqrt.columns, result["importances_mean"]))
top_20_features = pd.DataFrame(sorted(feature_list, key=lambda x: x[1], reverse=True)[:20], columns=["Feature", "Importance"])

print("\nTop 20 Features:")
print(top_20_features)

# Plot feature importance
plt.figure(figsize=(12, 6))
plt.barh(top_20_features["Feature"], top_20_features["Importance"])
plt.title("SVR's Feature Importances")
plt.xlabel("Importance Score")
plt.ylabel("Feature")
plt.gca().invert_yaxis()
plt.tight_layout()
plt.show()

"""# Model 5: SVR on features (inverse_transfrom(sqrt y_pred) vs. y_test)"""

# Train the SVR model
svr_model = SVR(kernel='rbf', C=100, epsilon=0.1)
svr_model.fit(X_train_sqrt, y_train_sqrt)

# Predict on test data
svr_y_pred = svr_model.predict(X_test_sqrt)

class SqrtTransformer():
    def __init__(self, power=1/2):
        self.power = power

    def fit(self, X):
        return self

    def transform(self, X):
        return X ** self.power

    def fit_transform(self, X):
        return self.fit(X).transform(X)

    def inverse_transform(self, X):
        return np.power(X, 1/self.power)

y_tf = SqrtTransformer()
svr_y_pred = y_tf.inverse_transform(svr_y_pred.reshape(-1, 1))

# Visualization: Actual vs. Predicted Wage
plt.figure(figsize=(10, 6))
plt.scatter(y_test, svr_y_pred, alpha=0.5)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
plt.title("Actual vs Predicted Wage")
plt.xlabel("Actual Wage")
plt.ylabel("Predicted Wage")
plt.show()

# Calculate metrics
svr_mse = mean_squared_error(y_test, svr_y_pred)
svr_r2 = r2_score(y_test, svr_y_pred)

# Print performance metrics
print(f"SVR - Mean Squared Error: {svr_mse}")
print(f"SVR - R² Score: {svr_r2}")

# Visualize feature importance for the SVR model
result = permutation_importance(svr_model, X_test_sqrt, y_test, n_repeats=1, random_state=42)
feature_list = list(zip(X_test_sqrt.columns, result["importances_mean"]))
top_20_features = pd.DataFrame(sorted(feature_list, key=lambda x: x[1], reverse=True)[:20], columns=["Feature", "Importance"])

print("\nTop 20 Features:")
print(top_20_features)

# Plot feature importance
plt.figure(figsize=(12, 6))
plt.barh(top_20_features["Feature"], top_20_features["Importance"])
plt.title("SVR's Feature Importances")
plt.xlabel("Importance Score")
plt.ylabel("Feature")
plt.gca().invert_yaxis()
plt.tight_layout()
plt.show()

"""# Model 6: SVR on XGBoost's top 20 features (sqrt y_pred vs. sqrt y_test)"""

# Subset data for XGBoost's top 20 features
XGBoost_features = ['Ball Control', 'Dribbling', 'Slide Tackle', 'Stand Tackle', 'Aggression',
                 'Reactions', 'Att. Position', 'Interceptions', 'Vision', 'Composure',
                 'Crossing', 'Short Pass', 'Long Pass', 'Acceleration', 'Stamina',
                 'Strength', 'Balance', 'Sprint Speed', 'Agility', 'Jumping']

X_XGBoost_train = X_train_sqrt[XGBoost_features]
X_XGBoost_test = X_test_sqrt[XGBoost_features]

# Train the SVR model
svr_XGBoost_model = SVR(kernel='rbf', C=100, epsilon=0.1)
svr_XGBoost_model.fit(X_XGBoost_train, y_train_sqrt)

# Predict on test data
svr_XGBoost_y_pred = svr_XGBoost_model.predict(X_XGBoost_test)

# Visualization: Actual vs. Predicted Wage
plt.figure(figsize=(10, 6))
plt.scatter(y_test_sqrt, svr_XGBoost_y_pred, alpha=0.5)
plt.plot([y_test_sqrt.min(), y_test_sqrt.max()], [y_test_sqrt.min(), y_test_sqrt.max()], 'r--', lw=2)
plt.title("Actual vs Predicted Wage")
plt.xlabel("Actual Wage")
plt.ylabel("Predicted Wage")
plt.show()

# Calculate metrics
svr_XGBoost_mse = mean_squared_error(y_test_sqrt, svr_XGBoost_y_pred)
svr_XGBoost_r2 = r2_score(y_test_sqrt, svr_XGBoost_y_pred)

# Print performance metrics
print(f"SVR on XGBoost's Top 20 Features - Mean Squared Error: {svr_XGBoost_mse}")
print(f"SVR on XGBoost's Top 20 Features - R² Score: {svr_XGBoost_r2}")

# Visualize feature importance for XGBoost's top 20 features
result = permutation_importance(svr_XGBoost_model, X_XGBoost_test, y_test_sqrt, n_repeats=1, random_state=42)
feature_list = list(zip(X_XGBoost_test.columns, result["importances_mean"]))
top_20_features = pd.DataFrame(sorted(feature_list, key=lambda x: x[1], reverse=True)[:20], columns=["Feature", "Importance"])

print("\nTop 20 Features:")
print(top_20_features)

# Plot feature importance
plt.figure(figsize=(12, 6))
plt.barh(top_20_features["Feature"], top_20_features["Importance"])
plt.title("SVR's Feature Importances (XGBoost's Top 20)")
plt.xlabel("Importance Score")
plt.ylabel("Feature")
plt.gca().invert_yaxis()
plt.tight_layout()
plt.show()

"""# Model 7: SVR on XGBoost's top 20 features (inverse_transform(sqrt y_pred) vs. y_test)"""

# Subset data for XGBoost's top 20 features
XGBoost_features = ['Ball Control', 'Dribbling', 'Slide Tackle', 'Stand Tackle', 'Aggression',
                 'Reactions', 'Att. Position', 'Interceptions', 'Vision', 'Composure',
                 'Crossing', 'Short Pass', 'Long Pass', 'Acceleration', 'Stamina',
                 'Strength', 'Balance', 'Sprint Speed', 'Agility', 'Jumping']

X_XGBoost_train = X_train_sqrt[XGBoost_features]
X_XGBoost_test = X_test_sqrt[XGBoost_features]

# Train the SVR model
svr_XGBoost_model = SVR(kernel='rbf', C=100, epsilon=0.1)
svr_XGBoost_model.fit(X_XGBoost_train, y_train_sqrt)

# Predict on test data
svr_XGBoost_y_pred = svr_XGBoost_model.predict(X_XGBoost_test)

class SqrtTransformer():
    def __init__(self, power=1/2):
        self.power = power

    def fit(self, X):
        return self

    def transform(self, X):
        return X ** self.power

    def fit_transform(self, X):
        return self.fit(X).transform(X)

    def inverse_transform(self, X):
        return np.power(X, 1/self.power)

y_tf = SqrtTransformer()
svr_XGBoost_y_pred = y_tf.inverse_transform(svr_XGBoost_y_pred.reshape(-1, 1))

# Visualization: Actual vs. Predicted Wage
plt.figure(figsize=(10, 6))
plt.scatter(y_test, svr_XGBoost_y_pred, alpha=0.5)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
plt.title("Actual vs Predicted Wage")
plt.xlabel("Actual Wage")
plt.ylabel("Predicted Wage")
plt.show()

# Calculate metrics
svr_XGBoost_mse = mean_squared_error(y_test, svr_XGBoost_y_pred)
svr_XGBoost_r2 = r2_score(y_test, svr_XGBoost_y_pred)

# Print performance metrics
print(f"SVR on XGBoost's Top 20 Features - Mean Squared Error: {svr_XGBoost_mse}")
print(f"SVR on XGBoost's Top 20 Features - R² Score: {svr_XGBoost_r2}")

# Visualize feature importance for XGBoost's top 20 features
result = permutation_importance(svr_XGBoost_model, X_XGBoost_test, y_test, n_repeats=1, random_state=42)
feature_list = list(zip(X_XGBoost_test.columns, result["importances_mean"]))
top_20_features = pd.DataFrame(sorted(feature_list, key=lambda x: x[1], reverse=True)[:20], columns=["Feature", "Importance"])

print("\nTop 20 Features:")
print(top_20_features)

# Plot feature importance
plt.figure(figsize=(12, 6))
plt.barh(top_20_features["Feature"], top_20_features["Importance"])
plt.title("SVR's Feature Importances (XGBoost's Top 20)")
plt.xlabel("Importance Score")
plt.ylabel("Feature")
plt.gca().invert_yaxis()
plt.tight_layout()
plt.show()

"""# Model 8: SVR on Preprocessed's top 20 features (sqrt y_pred vs. sqrt y_test)"""

# Subset data for Preprocessed's top 20 features
Preprocessed_features = [
    'overall_score', 'position_score', 'height', 'weight', 'age', 'Ball Control',
    'Dribbling', 'Slide Tackle', 'Stand Tackle', 'Aggression', 'Reactions',
    'Att. Position', 'Interceptions', 'Vision', 'Composure', 'Crossing',
    'Short Pass', 'Long Pass', 'Acceleration', 'Stamina', 'Strength', 'Balance',
    'Sprint Speed', 'Agility', 'Jumping'
]

X_Preprocessed_train = X_train_sqrt[Preprocessed_features]
X_Preprocessed_test = X_test_sqrt[Preprocessed_features]

# Train the SVR model
svr_Preprocessed_model = SVR(kernel='rbf', C=100, epsilon=0.1)
svr_Preprocessed_model.fit(X_Preprocessed_train, y_train_sqrt)

# Predict on test data
svr_Preprocessed_y_pred = svr_Preprocessed_model.predict(X_Preprocessed_test)

# Calculate metrics
svr_Preprocessed_mse = mean_squared_error(y_test_sqrt, svr_Preprocessed_y_pred)
svr_Preprocessed_r2 = r2_score(y_test_sqrt, svr_Preprocessed_y_pred)

# Visualization: Actual vs. Predicted Wage
plt.figure(figsize=(10, 6))
plt.scatter(y_test_sqrt, svr_Preprocessed_y_pred, alpha=0.5)
plt.plot([y_test_sqrt.min(), y_test_sqrt.max()], [y_test_sqrt.min(), y_test_sqrt.max()], 'r--', lw=2)
plt.title("Actual vs Predicted Wage")
plt.xlabel("Actual Wage")
plt.ylabel("Predicted Wage")
plt.show()

# Print performance metrics
print(f"SVR on Preprocessed's Top 20 Features - Mean Squared Error: {svr_Preprocessed_mse}")
print(f"SVR on Preprocessed's Top 20 Features - R² Score: {svr_Preprocessed_r2}")

# Visualize feature importance for Preprocessed's top 20 features
result = permutation_importance(svr_Preprocessed_model, X_Preprocessed_test, y_test_sqrt, n_repeats=1, random_state=42)
feature_list = list(zip(X_Preprocessed_test.columns, result["importances_mean"]))
top_20_features = pd.DataFrame(sorted(feature_list, key=lambda x: x[1], reverse=True)[:20], columns=["Feature", "Importance"])

print("\nTop 20 Features:")
print(top_20_features)

# Plot feature importance
plt.figure(figsize=(12, 6))
plt.barh(top_20_features["Feature"], top_20_features["Importance"])
plt.title("SVR's Feature Importances (Preprocessed's Top 20)")
plt.xlabel("Importance Score")
plt.ylabel("Feature")
plt.gca().invert_yaxis()
plt.tight_layout()
plt.show()

"""# Model 9: SVR on Preprocessed's top 20 features (inverse_transform(sqrt y_pred) vs. y_test)"""

# Subset data for Preprocessed's top 20 features
Preprocessed_features = [
    'overall_score', 'position_score', 'height', 'weight', 'age', 'Ball Control',
    'Dribbling', 'Slide Tackle', 'Stand Tackle', 'Aggression', 'Reactions',
    'Att. Position', 'Interceptions', 'Vision', 'Composure', 'Crossing',
    'Short Pass', 'Long Pass', 'Acceleration', 'Stamina', 'Strength', 'Balance',
    'Sprint Speed', 'Agility', 'Jumping'
]

X_Preprocessed_train = X_train_sqrt[Preprocessed_features]
X_Preprocessed_test = X_test_sqrt[Preprocessed_features]

# Train the SVR model
svr_Preprocessed_model = SVR(kernel='rbf', C=100, epsilon=0.1)
svr_Preprocessed_model.fit(X_Preprocessed_train, y_train_sqrt)

# Predict on test data
svr_Preprocessed_y_pred = svr_Preprocessed_model.predict(X_Preprocessed_test)

class SqrtTransformer():
    def __init__(self, power=1/2):
        self.power = power

    def fit(self, X):
        return self

    def transform(self, X):
        return X ** self.power

    def fit_transform(self, X):
        return self.fit(X).transform(X)

    def inverse_transform(self, X):
        return np.power(X, 1/self.power)

y_tf = SqrtTransformer()
svr_Preprocessed_y_pred = y_tf.inverse_transform(svr_Preprocessed_y_pred.reshape(-1, 1))

# Calculate metrics
svr_Preprocessed_mse = mean_squared_error(y_test, svr_Preprocessed_y_pred)
svr_Preprocessed_r2 = r2_score(y_test, svr_Preprocessed_y_pred)

# Visualization: Actual vs. Predicted Wage
plt.figure(figsize=(10, 6))
plt.scatter(y_test, svr_Preprocessed_y_pred, alpha=0.5)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
plt.title("Actual vs Predicted Wage")
plt.xlabel("Actual Wage")
plt.ylabel("Predicted Wage")
plt.show()

# Print performance metrics
print(f"SVR on Preprocessed's Top 20 Features - Mean Squared Error: {svr_Preprocessed_mse}")
print(f"SVR on Preprocessed's Top 20 Features - R² Score: {svr_Preprocessed_r2}")

# Visualize feature importance for Preprocessed's top 20 features
result = permutation_importance(svr_Preprocessed_model, X_Preprocessed_test, y_test, n_repeats=1, random_state=42)
feature_list = list(zip(X_Preprocessed_test.columns, result["importances_mean"]))
top_20_features = pd.DataFrame(sorted(feature_list, key=lambda x: x[1], reverse=True)[:20], columns=["Feature", "Importance"])

print("\nTop 20 Features:")
print(top_20_features)

# Plot feature importance
plt.figure(figsize=(12, 6))
plt.barh(top_20_features["Feature"], top_20_features["Importance"])
plt.title("SVR's Feature Importances (Preprocessed's Top 20)")
plt.xlabel("Importance Score")
plt.ylabel("Feature")
plt.gca().invert_yaxis()
plt.tight_layout()
plt.show()

