# -*- coding: utf-8 -*-
"""Preprocess.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1w--Uag6RpSA8z0R09ak0iuAzQZ_erPb9
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from xgboost import plot_importance

from google.colab import files
files.upload()

# Load the CSV file
raw_data = pd.read_csv('player_stats.csv')

print(raw_data.shape)
raw_data.head()

raw_data.columns

# Basic data cleaning
data = raw_data.copy()

# Turn height from str "X cm" into float. Weight from "X kg" into float.
def convert_hw(x):
    if type(x) == str:
        return float(x.split(' ')[0])
    else:
        return x
data['height'] = data['height'].apply(convert_hw)
data['weight'] = data['weight'].apply(convert_hw)

# Replace empty values with averages
data['height'] = data['height'].fillna(data['height'].mean())
data['weight'] = data['weight'].fillna(data['weight'].mean())

# Drop value because it's not useful
data = data.drop('name', axis=1)
data = data.drop('value', axis=1)

# Drop defence avg and marking because they are all nan
data = data.drop('defence_avg', axis=1)
data = data.drop('Marking', axis=1)

# Turn wage from str "$X" into float
def convert_wage(x):
    if type(x) == str:
        return float(x[1:])
    else:
        return x
data['wage'] = data['wage'].apply(convert_wage)

# Turn pref foot into 0/1
def convert_foot(x):
    if x == 'Right':
        return 0
    else:
        return 1
data['pref_foot'] = data['pref_foot'].apply(convert_foot)

print("Basic data cleaning done")
pd.set_option('display.max_columns', None)
data.head()

# Drop rows with NaN wages
data = data.dropna(subset=['wage'])

print(data.shape)

from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import mean_squared_error, r2_score

# Split the data into training and testing sets
X = data.drop('wage', axis=1)
y = data['wage']

def basic_proprocessing(X, y):
    categorical_columns = ['birthdate', 'pref_pos', 'work_rate', 'joined_club', 'contract_expires']
    label_encoder = LabelEncoder()

    for column in categorical_columns:
        X[column] = label_encoder.fit_transform(X[column].astype(str))

    indices = np.arange(X.shape[0])
    X_train, X_test, y_train, y_test, train_idx, test_idx = train_test_split(X, y, indices, test_size=0.2, random_state=42)
    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train)
    X_test = scaler.transform(X_test)

    return X_train, X_test, y_train, y_test, train_idx, test_idx

X_train, X_test, y_train, y_test, train_idx, test_idx = basic_proprocessing(X.copy(), y.copy())
print(X_train.shape, X_test.shape)

import xgboost as xgb
model = xgb.XGBRegressor(random_state=42)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f'Mean Squared Error: {mse}')
print(f'R2 Score: {r2}')

# Visualize feature importance
plt.figure(figsize=(10, 8))
plot_importance(model, max_num_features=20)
plt.title("Top 20 Important Features")
plt.show()

plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred, alpha=0.5)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
plt.xlabel("Actual Wage")
plt.ylabel("Predicted Wage")
plt.title("Actual vs Predicted Wage")
plt.show()

# More preprocessing. See wage distribution.
plt.hist(y, bins=50)
plt.xlabel('Wage')
plt.ylabel('Frequency')
plt.xlim(0, 200)
plt.title('Wage distribution')
plt.show()

# Log transform the wage
dlogy = np.log(y)
plt.hist(dlogy, bins=50)
plt.xlabel('Log Wage')
plt.ylabel('Frequency')

# Squared root transform the wage. Led to best results in practice.
ysqrt = y ** 1/2
plt.hist(ysqrt, bins=50)
plt.xlabel('Sqrt Wage')
plt.ylabel('Frequency')
plt.show()

# Box Cox
from scipy.stats import boxcox
bcy, lambda_param = boxcox(y)
plt.hist(bcy, bins=50)
plt.xlabel('Box Cox Wage')
plt.ylabel('Frequency')

# Yeo Johnson
from sklearn.preprocessing import PowerTransformer
yj = PowerTransformer(method='yeo-johnson')
yjy = yj.fit_transform(y.values.reshape(-1, 1))
plt.hist(yjy, bins=50)
plt.xlabel('Yeo Johnson Wage')
plt.ylabel('Frequency')

# More preprocessing. See age distribution.
plt.hist(X['age'], bins=50)
plt.xlabel('Age')
plt.ylabel('Frequency')
plt.title('Age distribution')
plt.show()

# More preprocessing. See height weight distribution.
for column in ['height', 'weight']:
    plt.hist(X[column], bins=50)
    plt.xlabel(column)
    plt.ylabel('Frequency')
    plt.title(f'{column} distribution')
    plt.show()

# More preprocessing. Check birthdate format.
X['birthdate'].head()
pd.to_datetime(X['birthdate'], format='mixed').head()

# More preprocessing. Check joined club format and contract expires format.
X['joined_club'][167]

# Extract year. Take last
# Replace nan in contract expires with mean
# X['contract_expires'].str.split(' ').str[-1].astype(int).head()

#
filled_ce = X['contract_expires'].replace(np.nan, 'nan')
mean = filled_ce[filled_ce != 'nan'].str.split(' ').str[-1].astype(int).mean()
filled_ce = filled_ce.replace('nan', "dummy " + str(mean))

filled_ce = filled_ce.str.split(' ').str[-1].astype(float).apply(np.ceil).astype(int)

filled_ce.head()

# Check joined club year

filled_jc = X['joined_club']
years = filled_jc.str.split(' ').str[-1]
def is_convertible(x):
    try:
        float(x)
        return True
    except Exception as e:
        return False
valid_mask = years.apply(is_convertible)
valid_mean = years[valid_mask].astype(float).mean()

def convert(x):
    try:
        return int(x)
    except Exception as e:
        return valid_mean
years = years.apply(convert)

# More preprocessing. See pref_pos distribution.
print(X['pref_pos'].value_counts())

# More preprocessing. See score distribution.
for column in ['overall_score', 'position_score', 'height', 'weight', 'age', 'Ball Control', 'Dribbling', 'Slide Tackle', 'Stand Tackle', 'Aggression', 'Reactions', 'Att. Position', 'Interceptions', 'Vision', 'Composure', 'Crossing', 'Short Pass', 'Long Pass', 'Acceleration', 'Stamina', 'Strength', 'Balance', 'Sprint Speed', 'Agility', 'Jumping', 'Heading', 'Shot Power', 'Finishing', 'Long Shots', 'Curve', 'FK Acc.', 'Penalties', 'Volleys', 'GK Positioning', 'GK Diving', 'GK Handling', 'GK Kicking', 'GK Reflexes']:
    plt.hist(data[column], bins=20)
    plt.title(column)
    plt.show()

# More preprocessing. Check weak foot and skill moves
for column in ['weak_foot', 'skill_moves']:
    plt.hist(data[column], bins=5)
    plt.title(column)
    plt.show()

# More preprocessing.
from sklearn.preprocessing import QuantileTransformer, RobustScaler
from tqdm import tqdm

class LogTransformer():
    def __init__(self, base):
        self.base = base

    def fit(self, X):
        return self

    def transform(self, X):
        return np.log(X) / np.log(self.base)

    def fit_transform(self, X):
        return self.fit(X).transform(X)

    def inverse_transform(self, X):
        return np.power(X, self.base)

class SqrtTransformer():
    def __init__(self, power=1/2):
        self.power = power

    def fit(self, X):
        return self

    def transform(self, X):
        return X ** self.power

    def fit_transform(self, X):
        return self.fit(X).transform(X)

    def inverse_transform(self, X):
        return np.power(X, 1/self.power)

def more_preprocessing(X, y, train_idx, test_idx):
    # Not sure if useful
    X = X.drop('work_rate', axis=1)
    X = X.drop('contract_expires', axis=1)

    # Create age categories [0-20, 20-30, 30-40, 40-100]. 0 for young & old. 1 for prime.
    X['age_category'] = pd.cut(X['age'], bins=[0, 20, 30, 40, 100], labels=[0, 1, 1, 0], ordered=False).astype(int)

    # Tall is good in general.
    # Create height categories [0-170, 170-180, 180-190, 190-210]. 0 for short & 1 for tall.
    X['height_category'] = pd.cut(X['height'], bins=[0, 180, 1000], labels=[0, 1], ordered=False).astype(int)

    # Create weight categories [0-50, 50-70, 70-90, 90-200]. 0 for light & 1 for heavy.
    X['weight_category'] = pd.cut(X['weight'], bins=[0, 70, 1000], labels=[0, 1], ordered=False).astype(int)

    categorical_columns = ['birthdate', 'pref_pos', 'joined_club']
    label_encoder = LabelEncoder()

    for column in categorical_columns:
        X[column] = label_encoder.fit_transform(X[column].astype(str))

    # Split pandas dataframe into training and testing sets
    X_train = X.iloc[train_idx]
    X_test = X.iloc[test_idx]
    y_train = y.iloc[train_idx]
    y_test = y.iloc[test_idx]

    # Bimodal data
    # - Ball Control (2 peaks: 20, 65. trough 30)
    # - Dribbling (2 peaks: 10, 65. trough 25)
    # - Slide Tackle (2 peaks: 20, 65. trough 40)
    # - Stand Tackle (2 peaks: 20, 65. trough 40)
    # - Att. Position (2 peaks: 10, 60. trough 20)
    # - Interceptions (2 peaks: 20, 65. trough 40)
    # - Crossing (2 peaks: 10, 65. trough 20)
    # - Short Pass (2 peaks: 25, 65. trough 40)
    # - Stamina (2 peaks: 30, 75. trough 45)
    # - Heading (2 peaks: 10, 60. trough 25)
    # - Curve (2 peaks: 10, 50. trough 20)
    # - Penalties (2 peaks: 10, 55. trough 25)
    bimodal_categories = ['Ball Control', 'Dribbling', 'Slide Tackle', 'Stand Tackle', 'Att. Position', 'Interceptions', 'Crossing', 'Short Pass', 'Stamina', 'Heading', 'Curve', 'Penalties']
    troughs = [30, 25, 40, 40, 20, 40, 20, 40, 45, 25, 20, 25]

    for i, column in tqdm(enumerate(bimodal_categories), total=len(bimodal_categories)):
        trough = troughs[i]
        bool_column = column + '_bool'
        X_train = X_train.assign(
            **{bool_column: lambda df: df[column].apply(lambda x: 0 if x < trough else 1)}
        )
        X_test = X_test.assign(
            **{bool_column: lambda df: df[column].apply(lambda x: 0 if x < trough else 1)}
        )

        # Push all values below trough to -20 to further separate the two peaks.
        new_column = column + '_new'
        X_train = X_train.assign(
            **{new_column: lambda df: df[column].apply(lambda x: 0 if x < trough else x)}
        )
        X_test = X_test.assign(
            **{new_column: lambda df: df[column].apply(lambda x: 0 if x < trough else x)}
        )

        scaler = RobustScaler()
        scaler.fit(X_train[new_column].values.reshape(-1, 1)[X_train[new_column] != 0])
        X_train = X_train.assign(
            **{
                new_column:
                    lambda df: df[new_column].apply(lambda x: 0 if x == 0 else scaler.transform(np.array(x).reshape(-1, 1)).item())
            }
        )
        X_test = X_test.assign(
            **{
                new_column:
                    lambda df: df[new_column].apply(lambda x: 0 if x == 0 else scaler.transform(np.array(x).reshape(-1, 1)).item())
            }
        )

        X_train = X_train.assign(
            **{new_column: lambda df: df[column].apply(lambda x: -20 if x < trough else x)}
        )
        X_test = X_test.assign(
            **{new_column: lambda df: df[column].apply(lambda x: -20 if x < trough else x)}
        )


    # Transform bimodal data

    # Clearly bimodal
    # - GK Positioning (2 peaks: 10, 60. separates at 30)
    # - GK Diving (2 peaks: 10, 65. separates at 30)
    # - GK Handling (2 peaks: 10, 60. separates at 30)
    # - GK Kicking (2 peaks: 10, 60. separates at 30)
    # - GK Reflexes (2 peaks: 10, 65. separates at 30)
    gk_categories = ['GK Positioning', 'GK Diving', 'GK Handling', 'GK Kicking', 'GK Reflexes']

    # Set all low values to 0 and standardize the rest
    for column in gk_categories:
        bool_column = column + '_bool'
        X_train = X_train.assign(
            **{bool_column: lambda df: df[column].apply(lambda x: 0 if x < 30 else 1)}
        )
        X_test = X_test.assign(
            **{bool_column: lambda df: df[column].apply(lambda x: 0 if x < 30 else 1)}
        )

        new_column = column + '_new'
        X_train = X_train.assign(
            **{new_column: lambda df: df[column].apply(lambda x: 0 if x < 30 else x)}
        )
        X_test = X_test.assign(
            **{new_column: lambda df: df[column].apply(lambda x: 0 if x < 30 else x)}
        )

        scaler = StandardScaler()
        scaler.fit(X_train[new_column].values.reshape(-1, 1)[X_train[new_column] != 0])
        X_train = X_train.assign(
            **{
                new_column:
                    lambda df: df[new_column].apply(lambda x: 0 if x == 0 else scaler.transform(np.array(x).reshape(-1, 1)).item())
            }
        )
        X_test = X_test.assign(
            **{
                new_column:
                    lambda df: df[new_column].apply(lambda x: 0 if x == 0 else scaler.transform(np.array(x).reshape(-1, 1)).item())
            }
        )

    # Transform wage
    y_tf = SqrtTransformer()
    y_train = y_tf.fit_transform(y_train.values.reshape(-1, 1))
    return X_train, X_test, y_train, y_test, y_tf

X_train, X_test, y_train, y_test, y_tf = more_preprocessing(X.copy(), y.copy(), train_idx, test_idx)
# print(X_train)
X_train.head()

model = xgb.XGBRegressor(random_state=42)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
y_pred = y_tf.inverse_transform(y_pred.reshape(-1, 1))

mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f'Mean Squared Error: {mse}')
print(f'R2 Score: {r2}')

# Visualize feature importance
plt.figure(figsize=(10, 8))
plot_importance(model, max_num_features=20)
plt.title("Top 20 Important Features")
plt.show()

plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred, alpha=0.5)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
plt.xlabel("Actual Wage")
plt.ylabel("Predicted Wage")
plt.title("Actual vs Predicted Wage")
plt.show()

# Train MLP model
from sklearn.neural_network import MLPRegressor

model = MLPRegressor(random_state=42)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
y_pred = y_tf.inverse_transform(y_pred.reshape(-1, 1))

mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f'Mean Squared Error: {mse}')
print(f'R2 Score: {r2}')

plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred, alpha=0.5)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
plt.xlabel("Actual Wage")
plt.ylabel("Predicted Wage")
plt.title("Actual vs Predicted Wage")
plt.show()